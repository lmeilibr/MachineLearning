---
title: "MLearning"
author: "Leandro Meili"
date: "1/19/2017"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Machine Learning Final Project

In this report we are going to check the activity type from some wearables sensors. The goal is to predict the correct exercise type (A,B,C,D,E). The train data has ~ 20k observations.

## Choosing the Variables

```{r, echo=FALSE,message=FALSE}
library(AppliedPredictiveModeling)
library(caret)
library(ggplot2)
library(lattice)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(splines)
library(parallel)
library(survival)
library(lubridate)
library(forecast)
library(zoo)
library(e1071)
library(plyr)
library(randomForest)
library(ElemStatLearn)
library(mgcv)
```
Let`s take a look at our train data
```{r}
test <- read.csv("pml-testing.csv",header=TRUE)
train <- read.csv("pml-training.csv",header=TRUE)
dim(train)
summary(train$classe)
```

So, first, we will partition this raw data in a training (70%) and testing set (30%).
```{r}
set.seed(100)

inBuild <- createDataPartition(y=train$classe,p=0.7,list=FALSE)
training <- train[inBuild,]
testing <- train[-inBuild,]
```

## Model Testing

Reading the original paper from the brazilian researches, looks like that roll, pitch and accel are the most important variables. So, for each sensor (there are 4), we will pcik the roll_,pitch_ and total_accel, giving us 12 variables for the prediction.

methods:
  mod1: gbm
  mod2: random forest
  
```{r}
mod1 <- train(classe ~roll_belt + pitch_belt + total_accel_belt
              +roll_arm + pitch_arm + total_accel_arm +
                +roll_dumbbell+pitch_dumbbell+total_accel_dumbbell
              +roll_forearm+pitch_forearm+total_accel_forearm,method = "gbm", 
              data=training,verbose=FALSE)
mod2 <- train(classe ~roll_belt + pitch_belt + total_accel_belt
              +roll_arm + pitch_arm + total_accel_arm +
                +roll_dumbbell+pitch_dumbbell+total_accel_dumbbell
              +roll_forearm+pitch_forearm+total_accel_forearm,method = "rf", 
              data=training)

pred1 <- predict(mod1,testing)
pred2 <- predict(mod2,testing)

m1 <- confusionMatrix(pred1,testing$classe)
m2 <- confusionMatrix(pred2,testing$classe)
```
## Conclusions

Checking the accuracy of both models, we see that the randomForest gave us a very nice prediction ~98%, against 90% from the gbm method
```{r}
m1$overall
m2$overall
```
It will be clear when we check the confusion matrix for the random forest
```{r}
m2$table
```
So, with this good prediction, the method of choice is the RandomForest.


